#!/usr/bin/env python3
"""
Firehoseé…ä¿¡ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’èª¿æŸ»ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import boto3
import json
from datetime import datetime, timedelta

def check_firehose_errors():
    # SSLè­¦å‘Šã‚’ç„¡è¦–
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    # boto3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆï¼ˆSSLæ¤œè¨¼ç„¡åŠ¹ï¼‰
    logs_client = boto3.client(
        'logs',
        region_name='ap-northeast-1',
        verify=False
    )

    cloudwatch = boto3.client(
        'cloudwatch',
        region_name='ap-northeast-1',
        verify=False
    )

    print("ğŸ” Firehoseé…ä¿¡ã‚¨ãƒ©ãƒ¼èª¿æŸ»")
    print("=" * 50)

    # Firehoseãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—
    firehose_log_groups = [
        '/aws/kinesisfirehose/aws-ses-migration-prod-raw-logs',
        '/aws/kinesisfirehose/aws-ses-migration-prod-masked-logs'
    ]

    for log_group in firehose_log_groups:
        log_type = "Raw" if "raw-logs" in log_group else "ãƒã‚¹ã‚¯åŒ–"
        print(f"\nğŸ“‹ {log_type}ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒ :")

        try:
            # ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
            response = logs_client.describe_log_streams(
                logGroupName=log_group,
                orderBy='LastEventTime',
                descending=True,
                limit=3
            )

            if not response['logStreams']:
                print(f"   ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒ ãªã—")
                continue

            # æœ€æ–°ã®ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å–å¾—
            for stream in response['logStreams'][:2]:  # æœ€æ–°2å€‹
                stream_name = stream['logStreamName']
                print(f"\n   ã‚¹ãƒˆãƒªãƒ¼ãƒ : {stream_name}")

                # éå»2æ™‚é–“ã®ãƒ­ã‚°ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
                start_time = int((datetime.now() - timedelta(hours=2)).timestamp() * 1000)

                try:
                    events_response = logs_client.get_log_events(
                        logGroupName=log_group,
                        logStreamName=stream_name,
                        startTime=start_time,
                        limit=20
                    )

                    if events_response['events']:
                        print(f"   ãƒ­ã‚°ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(events_response['events'])}")
                        for event in events_response['events']:
                            timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)
                            message = event['message']
                            print(f"   [{timestamp}] {message}")

                            # S3ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’ç‰¹ã«ç¢ºèª
                            if any(keyword in message.lower() for keyword in ['access denied', 'forbidden', '403', 'bucket', 'permission']):
                                print(f"   ğŸš¨ S3ã‚¢ã‚¯ã‚»ã‚¹é–¢é€£ã‚¨ãƒ©ãƒ¼ç™ºè¦‹: {message}")
                    else:
                        print(f"   éå»2æ™‚é–“ã®ãƒ­ã‚°ã‚¤ãƒ™ãƒ³ãƒˆãªã—")

                except Exception as e:
                    print(f"   ãƒ­ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        except Exception as e:
            print(f"   ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒ ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

    # Firehoseãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ã‚¨ãƒ©ãƒ¼çŠ¶æ³ã‚‚ç¢ºèª
    print(f"\nğŸ“Š Firehoseã‚¨ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")

    streams = ['aws-ses-migration-prod-raw-logs-stream', 'aws-ses-migration-prod-masked-logs-stream']

    for stream_name in streams:
        stream_type = "Raw" if "raw-logs" in stream_name else "ãƒã‚¹ã‚¯åŒ–"
        print(f"\n   {stream_type}ã‚¹ãƒˆãƒªãƒ¼ãƒ  ({stream_name}):")

        try:
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¢ºèª
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=2)

            # S3é…ä¿¡ã‚¨ãƒ©ãƒ¼
            response = cloudwatch.get_metric_statistics(
                Namespace='AWS/KinesisFirehose',
                MetricName='DeliveryToS3.Success',
                Dimensions=[
                    {
                        'Name': 'DeliveryStreamName',
                        'Value': stream_name
                    }
                ],
                StartTime=start_time,
                EndTime=end_time,
                Period=300,
                Statistics=['Sum', 'Average']
            )

            if response['Datapoints']:
                print(f"   S3é…ä¿¡æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹: {len(response['Datapoints'])} ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ")
                for dp in sorted(response['Datapoints'], key=lambda x: x['Timestamp']):
                    print(f"     [{dp['Timestamp']}] æˆåŠŸ: {dp['Sum']}, å¹³å‡: {dp['Average']}")
            else:
                print(f"   S3é…ä¿¡æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹: ãƒ‡ãƒ¼ã‚¿ãªã—")

            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼
            response = cloudwatch.get_metric_statistics(
                Namespace='AWS/KinesisFirehose',
                MetricName='DeliveryToS3.DataFreshness',
                Dimensions=[
                    {
                        'Name': 'DeliveryStreamName',
                        'Value': stream_name
                    }
                ],
                StartTime=start_time,
                EndTime=end_time,
                Period=300,
                Statistics=['Average', 'Maximum']
            )

            if response['Datapoints']:
                print(f"   ãƒ‡ãƒ¼ã‚¿æ–°é®®åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {len(response['Datapoints'])} ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ")
                for dp in sorted(response['Datapoints'], key=lambda x: x['Timestamp']):
                    print(f"     [{dp['Timestamp']}] å¹³å‡: {dp['Average']}, æœ€å¤§: {dp['Maximum']}")

        except Exception as e:
            print(f"   ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    check_firehose_errors()

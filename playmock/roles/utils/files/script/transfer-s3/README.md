# transfer-s3

A tool that compresses files and moves them to S3 for backup to prevent storage exhaustion.

ストレージの枯渇を防ぐためにファイルを圧縮したりS3に移動してバックアップするツール

※バージョン履歴は末尾に記載しています。

## 概要

* 経過日数が指定より古くなったファイルを gzip 圧縮します(規定は30日)
* 経過日数が指定より古くなった(圧縮済みの)ファイルを暗号化した上でS3に移動します(規定は90日)
* 処理されたファイルはジャーナルファイルに記録されます。ジャーナルファイルは処理後 S3 にアップロードされます
* ジャーナルファイルには S3 に移動したファイルをローカルに復元するコマンド行が含まれています（[バックアップファイルの復元](#バックアップファイルの復元)を参照）
* ジャーナルファイルはローカルに最大7日分残ります
* --dry-run オプションで圧縮やS3への移動対象となるファイルを事前に確認できます

### 注意点

* 本ツールは root ユーザでの実行を想定しています
* S3 へファイルを転送するために [AWS CLI バージョン 2](https://docs.aws.amazon.com/ja_jp/cli/latest/userguide/getting-started-install.html) を利用します。root ユーザの環境にAWSの認証情報を設定してください。
* S3 へ転送するファイルが大量にある場合、暗号化のための一時ファイルでストレージが枯渇する恐れがあります。 特に初回実行の場合は `--dry-run` オプションを使い、移動ファイル数がほどほどになるよう --move-older-than の日数を長めに調整してください。 [初回実行](#初回実行) も参照してください。
* 暗号化にはユーザ `gooscp` のSSH用の鍵を固定的に使用します。このユーザはオプションで変更できません。他の環境で運用する場合は `constants.sh` の `CRYPT_KEY_OWNER` 値を変更する必要があります



## 使用例

http ログなどをS3の `bucket-http-log-backup` バケットに転送する場合のコマンド例を示します。

※ロングオプションとショートオプションの例を示しています。
※最初の例にのみロングオプションのパラメータの区切りとして '=' または半角スペースの例を示しています。他のロングオプションのパラメータ指定も同様ですのでコマンド例は '=' 区切りのみを示しています。
※さらに詳しい使い方や実行環境については [コマンド詳細](#コマンド詳細)を参照してください。

### オプションのデフォルト設定で使う

```
transfer-s3.sh backup-http-log-bucket /var/log/httpd
```

* `/var/log/httpd` 以下全てのディレクトリ階層のファイルがバックアップ対象となります
* 経過日数が30日以上古くなったファイルを gzip 圧縮します
* 経過日数が90日以上古くなった圧縮済みのファイルを s3://backup-http-log-bucket/<ホスト名> に転送します
* S3への転送に成功したファイルはローカルから削除（つまり移動）します


### 複数のディレクトリを指定する

```
transfer-s3.sh backup-http-log-bucket /var/log/httpd /var/app/log
```

* `/var/log/httpd` 以下全てのディレクトリ階層のファイルがバックアップ対象です
* `/var/app/log` 以下全てのディレクトリ階層のファイルがバックアップ対象です
* 経過日数が30日以上の古くなったファイルを gzip 圧縮します
* 経過日数が90日以上の古くなった圧縮済みのファイルを `s3://backup-http-log-bucket/<ホスト名>` に転送します
* ジャーナルファイルなどの一時ファイルは最初に指定した /var/log/httpd/.transfer-s3 ディレクトリに作成されます。


### 過去から一昨日までのファイルを圧縮する

`--gzip-older-than` オプションを最小値 1 にすると昨日より古いファイルが圧縮対象となります。

```
transfer-s3.sh --gzip-older-than=1 backup-http-log-bucket /var/log/httpd
```
または
```
transfer-s3.sh --gzip-older-than 1 backup-http-log-bucket /var/log/httpd
```
または
```
transfer-s3.sh -g 1 backup-http-log-bucket /var/log/httpd
```

### 1週間前までのファイルを残して、より古いファイルを圧縮しS3に移動する

```
transfer-s3.sh --gzip-older-than=7 --move-older-than=7 backup-http-log-bucket /var/log/httpd
```
または
```
transfer-s3.sh -g 7 -m 7 backup-http-log-bucket /var/log/httpd
```


### S3への転送に使うプロファイル名を指定する

AWSのプロファイル名 `backup-s3` の認証情報を使う場合

```
transfer-s3.sh --profile=backup-s3 backup-http-log-bucket /var/log/httpd
```
または
```
transfer-s3.sh -p backup-s3 backup-http-log-bucket /var/log/httpd
```

* aws-cli の指定したプロファイルの認証情報で S3 バケットにアクセスします
* プロファイル設定は root ユーザ環境に必要です


### バックアップ対象のファイルをワイルドカードで指定する

```
transfer-s3.sh --include='access_*,error_*' backup-http-log-bucket /var/log/httpd
```
または
```
transfer-s3.sh -i 'access_*,error_*' backup-http-log-bucket /var/log/httpd
```

* `/var/log/httpd` 下の全てのディレクトリ階層に含まれ、ファイル名が `access_*`, または `error_*` に一致するファイルを対象とします
* バックアップ元ディレクトリを二つ2以上指定した場合も、ワイルドカード指定はどちらのディレクトリに対しても有効です

### バックアップ対象ファイルを指定ディレクトリ直下のファイルに限定する

```
transfer-s3.sh --non-recursive backup-http-log-bucket /var/log/httpd
```
または
```
transfer-s3.sh -n backup-http-log-bucket /var/log/httpd
```

* `/var/log/httpd` ディレクトリ直下のファイルのみがバックアップ対象となります
* バックアップ元ディレクトリを二つ以上指定した場合も、指定ディレクトリの直下のファイルのみが対象です

### 1台のホストで複数の異なる設定のバックアップを行う

１台のホスト上で異なる設定（例えば `--non-recursive` オプション指定あり/なしなど）のバックアップを行いたい場合、`--journal-id` オプションでジャーナルファイル名の重複を避ける必要があります。

例： httpd ログとシステムログのバックアップそれぞれに、 journal-id 'weblog', 'syslog' を付ける

weblog
: `transfer-s3.sh --journal-id=weblog backup-http-log-bucket /var/log/httpd`
ジャーナルファイル名は `transfer-s3-journal-weblog-YYYYMMDD.txt` となる

syslog
: `transfer-s3.sh --journal-id=syslog --non-recursive --include='messages-*,secure-*' backup-http-log-bucket /var/log`
ジャーナルファイル名は `transfer-s3-journal-syslog-YYYYMMDD.txt` となる




### どのファイルがS3へ移動されるか事前に確認する

```
transfer-s3.sh --dry-run --verbose backup-http-log-bucket /var/log/httpd
```
または
```
transfer-s3.sh -R -v backup-http-log-bucket /var/log/httpd
```


## コマンド詳細

```
transfer-s3.sh [オプション] <S3バケット名> <バックアップ元ディレクトリ>
```

S3バケット名
: S3の転送先バケット名です。必ず指定してください。

バックアップ元ディレクトリ
: S3に転送したいファイルが格納されたディレクトリを指定します。必ず指定してください。 
指定したディレクトリ以下の全ての階層のディレクトリに含まれるファイルが対象となります。

### オプション

-1 | --one-by-one
: S3 へ１ファイルずつ移動します。バックアップ初回実行時に使います。このオプションを付けるとストレージ上のバックアップ作業領域が小さく済む代わりにバックアップ時間が長くなります。

-g | --gzip-older-than n
: ファイルの更新日が n 日より古いファイルを gzip 圧縮対象とします。
n は 1 より小さくできません。つまり昨日のファイルは常に対象外となります。
未指定時 30

-i | --include patterns
: バックアップ対象とするファイル名を patterns で指定します。複数のパターンをカンマで連結できます。指定できるのはファイル名にたいするパターンのみで、ワイルドカード文字(*?)が使用できます。  
例）--include='access_log*,error_log*'  
未指定時 拡張子が *.gz, *.zip 以外の全てのファイルが対象

-j | --journal-id id
: ジャーナルファイル名に追加の識別子を付けます。詳しくは[ジャーナルファイルのパス](#ジャーナルファイルのパス)を参照してください。

-m | --move-older-than n
: ファイルの更新日が n 日より古いファイルを S3への移動(ローカルからの削除)対象とします。  
n は --gzip-older-than オプションで指定した日数以上でなければなりません。
また 1 より小さくできません。つまり昨日のファイルは常に対象外となります。  
未指定時 90

-n | --non-recursive
: 指定したバックアップ元ディレクトリ直下のファイルのみをバックアップ対象とします。
未指定時 無効

-p | --profile <profile>
: aws-cli コマンドが使用するプロファイルを指定します。  
未指定時 'default'

-R | --dry-run
: Dry-Run モードで実行します。Dry-Runモードではファイルに対する実際の処理は行われません。ただしジャーナルファイルは常に更新されます。
未指定時 無効

-v | --verbose
: コンソール出力が冗長になります。主に処理中のファイルと操作内容が表示されるようになります。このオプションに関わらずジャーナルにはファイルに対する操作が記録されます。
未指定時 無効

-h | --help
: ヘルプを表示し、終了コード 1 で終了します。


-V | --version
: バージョン情報を表示し、終了コード 1 で終了します。




## 準備と実行環境

* aws-cli がインストールされている必要があります。
* aws s3 の指定バケットへ接続するための認証情報を事前に登録してください。
* aws s3 に接続するためのプロファイルとして 'default' 以外を指定することもできます。--profile [オプション](#オプション)を参照してください。
* aws s3 へのファイル転送に使用する通信帯域を 1Mb/s に制限しています。お使いのプロファイルに設定が無ければ自動的に追加されます。
* 以下の標準的なコマンドを使用します。もし無ければ事前にインストールしてください。  
find
gzip
openssl
ssh-keygen (必要に応じて)
* SSH の鍵ペアを暗号化に使います。鍵ペアが無ければ事前に作成してください。
コマンド例： `$ ssh-keygen -t rsa -m pem` で実行しエンターキーのみ入力して作成
* 鍵ペアファイルは必ず `gooscp` ユーザが所有している必要があります。具体的には `/home/gooscp/.ssh/id_rsa`, `/home/gooscp/.ssh/id_rsa.pub` です。
* 暗号化のために SSH の秘密鍵から証明書を自動的に作成して使用します。ファイルは `/home/gooscp/.ssh/id_rsa.crt` です。

## 運用

### 初回実行

本ツールは通常、 S3 へ転送するバックアップ対象ファイル全てを一括で暗号化するため一時的な作業領域として ストレージ を消費します。これは S3 への転送に `aws s3 sync` コマンドを使っているためです。この挙動は運用開始前の ストレージ 残容量が極端に少ない場合や S3 への移動対象ファイルが大量にある場合に ストレージ の枯渇を引き起こす恐れがあります。
ストレージ 枯渇を避けるため、通常運用を開始する前に初回実行として、`--one-by-one` オプションを付けて実行して下さい。ファイルの暗号化と S3 へのファイル移動を１ファイルずつ行うため作業領域として消費する ストレージ 使用サイズが一番大きなファイルのサイズ程度になります。
ただしオプション未指定時に比べ処理時間が増えます。


### 通常運用

通常は cron 設定で1日1回の頻度で実行します。
毎月 1日 午前 6時に実行する例を示します。

`00 06 01 * * gooscp /usr/local/bin/transfer-s3.sh backup-http-log-bucket /var/log/httpd >/dev/null 2>&1`

### ジャーナルファイルについて

ジャーナルファイルは transfer-s3 コマンドの処理結果を出力したものです。想定通りに処理されたかどうかを確認したり、S3 にバックアップしたファイルをローカルに復元したいときに参照します。
ジャーナルファイルはバックアップ完了後に S3 にアップロードされます。また、ローカルに最大７日分保持されます。


#### ジャーナルファイルのパス

ジャーナルファイルのファイル名書式とローカル及びS3上のファイルパスは以下の通りです。
注意）特に1台のホスト上で複数の異なる設定（オプションやバックアップ元など）で transfer-s3 コマンドを実行する場合はそれぞれのジャーナルファイルがユニークとなるように `--journal-id` オプションで識別子を追加するのを忘れないでください。 例えば httpログのバックアップとシステムログのバックアップを行う必要がある場合は、それぞれのコマンドに以下の例のようなオプションを追加してください。
ジャーナルIDの例）
httpのログ：`--journal-id=weblog`
システムのログ：`--journal-id=syslog`

ジャーナルファイル名
: 書式は `transfer-s3-journal-YYYYMMDD.txt` となります。`YYYYMMDD` はバックアップを実行した日付です。
ただし、`--journal-id=ジャーナルID` オプションを指定した場合は
`transfer-s3-journal-ジャーナルID-YYYYMMDD.txt`
となります。

ローカルのパス
: `<バックアップ対象ディレクトリ>/.transfer-s3/<ジャーナルファイル名>`
transfer-s3 コマンドに指定したバックアップ対象ディレクトリ（複数指定した場合は最初のディレクトリ）のワークディレクトリ `.transfer-s3` に作成されます。

S3にバックアップされたジャーナルファイルのパス
: `s3://<バケット名>/<ホスト名>/<ジャーナルファイル名>`
※ホスト名はバックアップを実行したサーバの名称で `hostname -s` コマンドの戻り値です。


### バックアップファイルの復元

S3 に移動したファイルをローカルに復元する作業を容易にするために、transfer-s3 はジャーナルファイルにファイル単位で復元するためのコマンド行を出力しています。復元コマンド行を実行することで S3 からのダウンロード、復号、圧縮ファイルの展開が行えます。


#### 復元環境

1. 復元作業はバックアップ時と同じ環境もしくは同じSSH鍵を持つ `gooscp` ユーザが存在する環境で行う必要があります。

2. 復元コマンドの実行は `root` で行ってください。
`root` で実行できないなど制限がある場合は、`gooscp` ユーザ環境の S3 プロファイルをバックアップ環境と同様に設定することで `gooscp` ユーザでも実施可能です。

#### 復元手順

1. ジャーナルファイルを入手する
ファイルの位置は[ジャーナルファイルのパス](#ジャーナルファイルのパス)を参照してください。

2. ジャーナルファイルから復元コマンド行を取得する
ジャーナルファイルの `file moved from '<バックアップ対象ファイルのパス>' to s3.` に一致する行の次行に `restore from s3: $ aws ...` という復元コマンド行があります。`$` 記号の後ろ `aws` から行末までが復元コマンド行です。
注意）復元コマンド行は1行でかつ長い文字列となりますので、ジャーナルファイルから取得する際は改行が入らないよう注意してください。 

3. ワークディレクトリを準備する
バックアップファイルを復元する為に一時ディレクトリを作成しカレントディレクトリとします。ファイルはバックアップ元のディレクトリ構造を含めカレントディレクトリに復元されます。以下はワークディレクトリを `restore` とした場合の実行例です。
`$ mkdir restore`
`$ cd restore`

4. 復元コマンドの実行
復元コマンド行は `root` で実行する必要があります。復元コマンド行の先頭に `sudo` を付けただけでは正しく復元されませんので注意してください。
`$ sudo -s`
`# aws s3 cp ...`以降省略


#### 並列、複数実行について

transfer-s3 は同時並列実行可能ですが、サーバ負荷及びネットワーク負荷を考慮して実行時間帯が重ならないよう調整することをお勧めします。
実行時間は対象ファイルの数、サイズ、S3転送時の帯域設定、`--one-by-one` オプションの有無によって異なります。ジャーナルの最後に開始時刻と終了時刻が出力されていますので参考にしてください。

1台のホスト上で複数の transfer-s3 コマンドを実行する場合は、ジャーナルファイルが重複しないよう `--journal-id` オプションでそれぞれに異なる識別子を付けてください。詳しくは[オプション](#オプション) 及び[ジャーナルファイルについて](#ジャーナルファイルについて) を参照してください。


## バージョン履歴

0.1.0 : 2023-06-08
: 初回リリース

0.1.1 : 2023-07-04
: オプション追加(--include, --non-recursive)
ホスト名はショートネームを利用するようにした
バックアップ元ディレクトリを複数指定可能とした

0.1.2 : 2023-07-19
: 未定義変数参照の不具合を改修
aws コマンドがバージョン 2 以降かどうかのチェックを追加
環境チェック時にプロファイル設定や暗号化用証明書作成などを行った際にコンソールにメッセージが出ていなかった点を改修
運用環境変更時に役立つコメントを contatns.sh に追記

0.1.3 : 2023-09-15
: オプション追加・変更
・`--one-by-one` オプションにより１ファイルずつ暗号化、アップロード、削除を行いストレージ使用量を最低限にするモードを追加
・`--journal-id=id` オプションによりジャーナルファイル名の重複を避けられるようにした
その他の変更：  
・journal ファイルに出力された復元コマンド行の各コマンドのうち、S3 からダウンロードしたファイルを削除する `rm` コマンドにオプション `-f` を追加した 
※version 0.1.3 より古い transfer-s3 がジャーナルに出力したリストアコマンド行を実行した場合、ファイルごとに削除確認プロンプトが表示されてしまいます。大量にリストアする場合は `rm` を `rm -f` に置換した後実行してください（ｽﾐﾏｾﾝ）
具体的な復元コマンドは以下のようになっています。
`aws s3 cp 's3://リストア対象パスとファイル名.gz.enc' './ダウンロード先パスとファイル名.gz.enc' && \\`
`openssl 復号コマンド中略 -out './復号先パスとファイル名.gz' && \\`
`rm -f './ダウンロード先パスとファイル名.gz.enc' && \\`
`gunzip './復号先パスとファイル名.gz'`




# 以上
